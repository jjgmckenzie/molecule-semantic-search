{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPeAm8n6cM5Z"
   },
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEgix9HRdzAL"
   },
   "source": [
    "## Library Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r 'lib/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.openai import gpt4\n",
    "from lib.display_md import display_md\n",
    "from lib.llama2 import llama2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyediting Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juding Criteria\n",
    "[From the hackathon Notion page.](https://samsungnext.notion.site/Next-Gen-AI-Hackathon-Attendee-Guide-bec2d308f82245bfbb885d1fa093521a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "judging_criteria = \"\"\"\n",
    "Judging Criteria\n",
    "\n",
    "There will be three award categories:\n",
    "\n",
    "- **Breakthrough Award:** The project that demonstrates outstanding deep core technical or architectural innovations that enable or leverage generative AI for mobile use cases.\n",
    "- **Edge Award:** The project with greatest impact that leverages only models that have been optimized and deployed locally on the device.\n",
    "- **Pioneer Award:** The project that most uniquely leverages mobile sensor, data, or services to create novel or more impactful mobile user experiences.\n",
    "\n",
    "All projects will be evaluated on the following criteria.\n",
    "\n",
    "- **Impact:** Does this project have the potential to impact millions - even billions - around the world?\n",
    "- **Creativity:** Does the project solve a problem in a differentiated or unique way?\n",
    "- **User Experience:** Does the project deliver a delightful user experience?\n",
    "- **Centrality of Generative AI:** Does generative AI play a critical role in enabling the solution?\n",
    "- **Technical feasibility:** Does the technical implementation work? If the project is not fully functional, could this approach work technically?\n",
    "- **Fidelity:** How “finished” is the project? How close is it to an alpha launch?\n",
    "\n",
    "Participants are expected share a 3-minute pitch deck including a demo and high-level architectural diagrams. We will have mentors available to help folks fine tune and prepare for the final presentations.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_proposal = \"\"\"\n",
    "﻿Proof of Concept Proposal: Automated Ontologization for Heterogeneous Experimental Data\n",
    "Toby Tobkin - Solutions Architect - toby@valuestream.ai\n",
    "\n",
    "Prepared for Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies\n",
    "Background\n",
    "A primary barrier to the widespread adoption of clean hydrogen fuel storage is discovering a practical material for Hydrogen Energy Devices. At the current rate of materials science advancement, some experts project that the discovery and adoption of requisite advanced materials such as catalysts and membrane materials could take until 2050. However, climate change and pollution are occurring rapidly, so it is critical to accelerate this R&D timeframe to 2035. The most significant barrier to accelerating this timeframe is the quantity of researcher toil required per cycle of advanced materials science (AES) experiments. The primary root cause of researcher toil is the human-inaccessibility of experimental data from applied energy materials research. This inaccessibility exists because no widely adopted ontology exists for applied energy materials research. Thus, experimental data is stored heterogeneously, effectively siloed data between scientific domains and individual labs. To overcome this, material scientists must manually de-silo from tens of millions of data points about materials and fabrication methods, drastically slowing down applied materials research. Due to intractable issues such as lab researcher turnover, we presume that AES data will remain heterogeneous without Practical Automated Ontologization for AES Heterogeneous Experimental Data (HED).\n",
    "\n",
    "Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies seeks research advancements to commercialize practical, clean hydrogen fuel storage. ValuestreamAI seeks a challenging, impactful engineering problem to solve.\n",
    "Programming Competition Venue & Scope\n",
    "The ValuestreamAI team will compete in the 2023 Samsung Gen AI programming competition in San Francisco.  The team comprises three engineers and one technical business analyst. Approximately one week of engineering preparation work is done prior to the competition. The competition is approximately ten hours of execution time. Thus, the scope must be limited while still shipping a usable product.\n",
    "Problem Statement\n",
    "Automate the classification of non-standardized CSV headers to Node Labels compliant with the Proposed EMMO Extension Ontology for Hydrogen Energy Conversion Materials Science. \n",
    "  \n",
    "Problem Selection Rationale\n",
    "Header Classification to Node Label was chosen because it is a microcosm of the AES HED problem.\n",
    "\n",
    "The problem was selected using the following process:\n",
    "1. The Client research team presented several relevant research problems. \n",
    "2. Sort by urgency to solve\n",
    "3. Tie-break by the impact of solving\n",
    "4. Filter by:\n",
    "   1. Estimated analysis scope under 70 hours\n",
    "   2. Estimated implementation scope under 30 hours\n",
    "\n",
    "Given additional time, we may also proof of concept Node Attribute classification.\n",
    "________________\n",
    "KPIs\n",
    "ValuestreamAI seeks to choose KPIs that are an accurate proxy for implementing Practical Automated Ontologization for AES HED. The following KPIs were chosen:\n",
    "\n",
    "    Precision\n",
    "\tPrecision of the classifier is paramount because a human user will distrust the inference system if they feel they cannot trust positive inferences\n",
    "\tRecall\n",
    "\tRecall determines the percent of researcher toil automated for the given subtask\n",
    "\tConfusion Matrix\n",
    "\tA slideshow-friendly version of Precision and Recall.\n",
    "\tRuntime Cost Per Million Rows\n",
    "\tDetermines the ongoing per-unit cost of testing and using the inference pipeline\n",
    "\tR&D Costs\n",
    "\tThe upfront costs. There should be an attainable cost curve for achieving useful milestones.\n",
    "\tLicensing Costs\n",
    "\tCosts related to licensing technology\n",
    "\tSuitability for On-prem Cluster\n",
    "\tHow compatible is the solution with the client research team's compute cluster?\n",
    "\tData Privacy\n",
    "\tIs data processed and stored in a secure manner that is verifyable by a layman?\n",
    "\tClient Satisfaction\n",
    "\tDoes the deliverable satisfy its intended purpose?\n",
    " \n",
    "Solution Constraints\n",
    "The proposed solution must:\n",
    "* Represent the larger problem of Practical Automated Ontologization for AES HED\n",
    "* Plausibly scale to reduce a top category of researcher toil by at least 90%\n",
    "* Be adaptable to support high-quality integration with neo4j and VIMI\n",
    "________________\n",
    "\n",
    "Hackathon Proposed Deliverables\n",
    "The deliverable is a Github Repo with the following contents:\n",
    "Jupyter Notebooks\n",
    "\tPython notebooks that reproduce the inference experiments for the problem under study.\n",
    "\tDevelopment Environment\n",
    "\tEnglish instructions and Linux scripts documenting how to reproduce the desktop environment for reproducing or extending the experiments delivered.\n",
    "\tWorkflows\n",
    "\tEnglish instructions and Linux scripts documenting how to reproduce or extend the experiments delivered.\n",
    "\tLive Training Recording\n",
    "\tUp to three hours of recorded live sessions for the client research team for training and analysis.\n",
    "\t\n",
    "\n",
    "The deliverable will have the following attributes: 1. Complementary to existing work, 2. MIT license, 3. High standard of readability\n",
    "\n",
    "Payment Terms\n",
    "ValuestreamAI requests payment only if the deliverable meets or exceeds the client research team's expectations. Payment shall be due NET60 from the day of invoice to the client research team. The requested payment amount is the approximate cost of competition preparation and travel expenses, CAD$4000. Engineering hours are granted pro bono for this project.\n",
    "\n",
    "Future Work\n",
    "The proposed deliverable is only a small slice of the larger problem of Practical Automated Ontologization for AES HED. The ValuestreamAI team is in the early stages of understanding the broader context of this research field. However, they understand the following future work is required:\n",
    "* Defining the complete engineering scope of Practical Automated Ontologization for AES HED\n",
    "* Inferring ontological relationships between heterogeneous data fields\n",
    "* Investigating the potential for collaboration with other research institutions to pool resources and data\n",
    "* Evaluating the effectiveness of the ontology in practice and making necessary adjustments based on feedback from researchers\n",
    "* Exploring the potential for machine learning algorithms to predict outcomes based on the AES data\n",
    "\n",
    "Jargon and Entities\n",
    "AES: Advanced Materials Science.\n",
    "HED: Heterogeneous Experimental Data.\n",
    "AES HED: The subproblem under research.\n",
    "Hydrogen Energy Devices: Water electrolyzers and fuel cells.\n",
    "FAIR: Findable, Accessible, Interoperable, and Reusable\n",
    "neo4j: an industry-standard graph database\n",
    "EMMO: EMMO, or the European Materials Modelling Ontology, is a versatile ontology for materials sciences developed by the European Materials Modelling Council. It consists of three levels: the top level defines real-world objects and introduces \"perspectives\" to reflect their pluralistic nature, the middle level contains specific perspectives that make EMMO applicable to various domains, and the bottom level contains ontologies of specific materials science domains. EMMO is used to standardize the knowledge representation of a domain, making it particularly useful in the context of FAIR (Findable, Accessible, Interoperable, Reusable) data generation.\n",
    "VIMI:  Virtual Materials Intelligence platform, is a system that integrates data-driven methods for materials science research. It uses the Python framework Django for seamless integration and data management. The platform is designed to handle data from fabrication workflows, measurements, and simulations and encourages researchers to share data to accelerate their research. VIMI is particularly useful in the field of energy materials, where it can assist in the screening of materials, experimental design, the optimization of workflows, and the orchestration of devices within self-driven labs. VIMI is a spin-off Project from the Institute of Energy and Climate Research, IEK-13 at Forschungszentrum Juelich.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyediting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_preamble = \"\"\"\n",
    "I am writing a talk track for a three minute video presentation for generative AI programming competition\n",
    "hosted by Samsung in San Francisco.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hackathon_judging_criteria_addressed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hackathon_judging_criteria_addressed(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble} \n",
    "    \n",
    "    1. Rate how well my talk track addresses each of the hackathon judging criterion\n",
    "    2. Rate how well my talk track suits each of the three winner categories\n",
    "\n",
    "    The talk track is given in <talk-track>. The judging criteria are provided in <judging-criteria>\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "\n",
    "    <judging-criteria>\n",
    "        {judging_criteria}\n",
    "    </judging-criteria>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## consistent_with_research_proposal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_with_research_proposal(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    Is the talk track inconsistent with the provided research proposal in any way?\n",
    "\n",
    "    The talk track is given in <talk-track>. The research proposal is given in <research-proposal>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "\n",
    "    <research-proposal>\n",
    "        {research_proposal}\n",
    "    </research-proposal>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## technical_fact_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def technical_fact_check(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    Are any of the claims made in the talk track potentially disputable by an educated observer? \n",
    "    Could any of the claims have the appearance of being disputable, even if they are technically accurate?\n",
    "\n",
    "    The talk track is given in <talk-track>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_talk_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_talk_time(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    At 140 wpm, approximately how many seconds will the following talk track take to read?\n",
    "\n",
    "    The talk track is given in <talk-track>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## includes_required_talking_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def includes_required_talking_points(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    Does the talk track given include all of the talking points in <talking-points>\n",
    "\n",
    "    The talk track is given in <talk-track>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "\n",
    "    <talking-points>\n",
    "        - The high level story is this: Toby immigrated to Canada and his goal is to hit $10k in profit building AI software via face to face local sales only\n",
    "        - We pitched this pilot to the lab last Tuesday, September 12\n",
    "        - We were offered the opportunity to pitch the research lab because we hosted a local picnic for AI developers.\n",
    "        - The developers on this solution all volunteered to do this project on under 24 hour notice, paid upon payment receipt from client\n",
    "        - A key factor in getting the pilot opportunity was our differentiated open source licensing\n",
    "    </talking-points>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## story_told_chronologically()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def story_told_chronologically(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    Is the narrative in the talk track given chronologically in a manner that is easy for an educated audience\n",
    "    to follow?\n",
    "\n",
    "    The talk track is given in <talk-track>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>    \n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft 1 - Just Read The Research Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided talk track and judging criteria, here's how your talk track addresses each of the hackathon judging criteria:\n",
       "\n",
       "1. **Impact:** Your project addresses a significant global issue - the need for clean hydrogen fuel storage. The potential impact is vast, as it could accelerate the discovery and adoption of advanced materials for Hydrogen Energy Devices. However, the talk track could emphasize more on how the project could potentially impact millions or billions of people around the world. Rating: 7/10\n",
       "\n",
       "2. **Creativity:** The project proposes a unique solution to a complex problem - automating the classification of non-standardized CSV headers to Node Labels compliant with the Proposed EMMO Extension Ontology for Hydrogen Energy Conversion Materials Science. This is a creative approach to a problem that slows down applied materials research. Rating: 8/10\n",
       "\n",
       "3. **User Experience:** The talk track doesn't explicitly address user experience. However, it does mention that the deliverable will have a high standard of readability, which suggests a focus on user experience. Rating: 5/10\n",
       "\n",
       "4. **Centrality of Generative AI:** The talk track doesn't explicitly mention the use of generative AI. However, the proposed solution involves automation and classification, which could potentially involve the use of generative AI. Rating: 5/10\n",
       "\n",
       "5. **Technical feasibility:** The talk track provides a detailed explanation of the problem and the proposed solution, suggesting that the approach is technically feasible. However, it doesn't explicitly address the technical feasibility of the project. Rating: 7/10\n",
       "\n",
       "6. **Fidelity:** The talk track suggests that the project is in the early stages of development, but it provides a clear plan for future work. Rating: 6/10\n",
       "\n",
       "As for the three winner categories:\n",
       "\n",
       "1. **Breakthrough Award:** The project proposes a novel solution to a significant problem, which could be seen as a technical or architectural innovation. However, it doesn't explicitly mention how it enables or leverages generative AI for mobile use cases. Rating: 6/10\n",
       "\n",
       "2. **Edge Award:** The talk track doesn't mention whether the models have been optimized and deployed locally on the device. Rating: 3/10\n",
       "\n",
       "3. **Pioneer Award:** The project leverages data in a novel way to solve a significant problem. However, it doesn't explicitly mention how it leverages mobile sensor, data, or services to create novel or more impactful mobile user experiences. Rating: 6/10\n",
       "\n",
       "Overall, the talk track provides a clear and detailed explanation of the problem and the proposed solution. However, it could benefit from more explicit connections to the judging criteria and the three winner categories."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hackathon_judging_criteria_addressed(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The talk track and the research proposal are identical. There is no inconsistency between the two. Both documents outline the same project, goals, problem statement, KPIs, solution constraints, proposed deliverables, payment terms, future work, and jargon and entities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "consistent_with_research_proposal(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The talk track seems to be well-researched and detailed, but there are a few points that could potentially be disputed by an educated observer:\n",
       "\n",
       "1. The claim that \"At the current rate of materials science advancement, some experts project that the discovery and adoption of requisite advanced materials such as catalysts and membrane materials could take until 2050.\" This is a prediction and could be disputed based on different expert opinions or advancements in the field.\n",
       "\n",
       "2. The statement that \"The most significant barrier to accelerating this timeframe is the quantity of researcher toil required per cycle of advanced materials science (AES) experiments.\" This could be disputed as there may be other significant barriers such as funding, technology limitations, or regulatory hurdles.\n",
       "\n",
       "3. The assertion that \"Due to intractable issues such as lab researcher turnover, we presume that AES data will remain heterogeneous without Practical Automated Ontologization for AES Heterogeneous Experimental Data (HED).\" This is a presumption and could be disputed based on different management practices or technological solutions.\n",
       "\n",
       "4. The claim that \"The proposed solution must... Plausibly scale to reduce a top category of researcher toil by at least 90%\" could be disputed as it is a prediction and the actual reduction in researcher toil could vary.\n",
       "\n",
       "5. The statement that \"ValuestreamAI requests payment only if the deliverable meets or exceeds the client research team's expectations.\" This could be disputed as it is subjective and depends on the client's expectations.\n",
       "\n",
       "6. The claim that \"The ValuestreamAI team is in the early stages of understanding the broader context of this research field.\" This could be disputed based on the team's experience and knowledge in the field.\n",
       "\n",
       "Even if these claims are technically accurate, they could appear disputable due to their predictive or subjective nature. It would be beneficial to provide more concrete evidence or data to support these claims where possible."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "technical_fact_check(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The talk track contains approximately 1,400 words. Given that the average speaking speed is 140 words per minute, it would take approximately 10 minutes to read the entire talk track. This is significantly longer than the three-minute time frame for the video presentation. You may need to condense or prioritize parts of the talk track to fit within the allotted time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimate_talk_time(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "includes_required_talking_points(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_told_chronologically(research_proposal)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cWp08IdDa_ok"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
