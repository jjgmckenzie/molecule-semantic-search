{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4fea561-94f0-43c6-9c2b-1dada0a24953",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display_md,tokencount\n",
      "File \u001b[0;32m~/src/valuestreamai/molecule-semantic-search/jupyter-notebooks/lib/tokencount.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_tokens_from_string\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m, encoding_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of tokens in a text string.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "source": [
    "!pip install -r 'lib/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983107d5-7273-4ad7-8dee-7ac7e469297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import display_md,tokencount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ebf3f36-8f54-46cd-ad75-fd6a7377e915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Test"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_md.display_md(\"# Test\")\n",
    "tokencount.tokencount(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32927043-b5de-44b1-83c2-59d9813f440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_pager = \"\"\"\n",
    "﻿Proof of Concept Proposal: Automated Ontologization for Heterogeneous Experimental Data\n",
    "Toby Tobkin - Solutions Architect - toby@valuestream.ai\n",
    "\n",
    "\n",
    "Prepared for Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies\n",
    "Background\n",
    "A primary barrier to the widespread adoption of clean hydrogen fuel storage is discovering a practical material for Hydrogen Energy Devices. At the current rate of materials science advancement, some experts project that the discovery and adoption of requisite advanced materials such as catalysts and membrane materials could take until 2050. However, climate change and pollution are occurring rapidly, so it is critical to accelerate this R&D timeframe to 2035. The most significant barrier to accelerating this timeframe is the quantity of researcher toil required per cycle of advanced materials science (AES) experiments. The primary root cause of researcher toil is the human-inaccessibility of experimental data from applied energy materials research. This inaccessibility exists because no widely adopted ontology exists for applied energy materials research. Thus, experimental data is stored heterogeneously, effectively siloed data between scientific domains and individual labs. To overcome this, material scientists must manually de-silo from tens of millions of data points about materials and fabrication methods, drastically slowing down applied materials research. Due to intractable issues such as lab researcher turnover, we presume that AES data will remain heterogeneous without Practical Automated Ontologization for AES Heterogeneous Experimental Data (HED).\n",
    "\n",
    "\n",
    "Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies seeks research advancements to commercialize practical, clean hydrogen fuel storage. ValuestreamAI seeks a challenging, impactful engineering problem to solve.\n",
    "Programming Competition Venue & Scope\n",
    "The ValuestreamAI team will compete in the 2023 Samsung Gen AI programming competition in San Francisco.  The team comprises three engineers and one technical business analyst. Approximately one week of engineering preparation work is done prior to the competition. The competition is approximately ten hours of execution time. Thus, the scope must be limited while still shipping a usable product.\n",
    "Problem Statement\n",
    "Automate the classification of non-standardized CSV headers to Node Labels compliant with the Proposed EMMO Extension Ontology for Hydrogen Energy Conversion Materials Science. \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "Problem Selection Rationale\n",
    "Header Classification to Node Label was chosen because it is a microcosm of the AES HED problem.\n",
    "\n",
    "\n",
    "The problem was selected using the following process:\n",
    "1. The Client research team presented several relevant research problems. \n",
    "2. Sort by urgency to solve\n",
    "3. Tie-break by the impact of solving\n",
    "4. Filter by:\n",
    "   1. Estimated analysis scope under 70 hours\n",
    "   2. Estimated implementation scope under 30 hours\n",
    "\n",
    "\n",
    "Given additional time, we may also proof of concept Node Attribute classification.\n",
    "________________\n",
    "KPIs\n",
    "ValuestreamAI seeks to choose KPIs that are an accurate proxy for implementing Practical Automated Ontologization for AES HED. The following KPIs were chosen:\n",
    "\n",
    "\n",
    "Precision\n",
    "\tPrecision of the classifier is paramount because a human user will distrust the inference system if they feel they cannot trust positive inferences\n",
    "\tRecall\n",
    "\tRecall determines the percent of researcher toil automated for the given subtask\n",
    "\tConfusion Matrix\n",
    "\tA slideshow-friendly version of Precision and Recall.\n",
    "\n",
    "\n",
    "\t  \n",
    "\n",
    "\tRuntime Cost Per Million Rows\n",
    "\tDetermines the ongoing per-unit cost of testing and using the inference pipeline\n",
    "\tR&D Costs\n",
    "\tThe upfront costs. There should be an attainable cost curve for achieving useful milestones.\n",
    "\tLicensing Costs\n",
    "\tCosts related to licensing technology\n",
    "\tSuitability for On-prem Cluster\n",
    "\tHow compatible is the solution with the client research team's compute cluster?\n",
    "\tData Privacy\n",
    "\tIs data processed and stored in a secure manner that is verifyable by a layman?\n",
    "\tClient Satisfaction\n",
    "\tDoes the deliverable satisfy its intended purpose?\n",
    "\tSolution Constraints\n",
    "The proposed solution must:\n",
    "* Represent the larger problem of Practical Automated Ontologization for AES HED\n",
    "* Plausibly scale to reduce a top category of researcher toil by at least 90%\n",
    "* Be adaptable to support high-quality integration with neo4j and VIMI\n",
    "________________\n",
    "Hackathon Proposed Deliverables\n",
    "The deliverable is a Github Repo with the following contents:\n",
    "Jupyter Notebooks\n",
    "\tPython notebooks that reproduce the inference experiments for the problem under study.\n",
    "\tDevelopment Environment\n",
    "\tEnglish instructions and Linux scripts documenting how to reproduce the desktop environment for reproducing or extending the experiments delivered.\n",
    "\tWorkflows\n",
    "\tEnglish instructions and Linux scripts documenting how to reproduce or extend the experiments delivered.\n",
    "\tLive Training Recording\n",
    "\tUp to three hours of recorded live sessions for the client research team for training and analysis.\n",
    "\t\n",
    "\n",
    "The deliverable will have the following attributes: 1. Complementary to existing work, 2. MIT license, 3. High standard of readability\n",
    "Payment Terms\n",
    "ValuestreamAI requests payment only if the deliverable meets or exceeds the client research team's expectations. Payment shall be due NET60 from the day of invoice to the client research team. The requested payment amount is the approximate cost of competition preparation and travel expenses, CAD$4000. Engineering hours are granted pro bono for this project.\n",
    "Future Work\n",
    "The proposed deliverable is only a small slice of the larger problem of Practical Automated Ontologization for AES HED. The ValuestreamAI team is in the early stages of understanding the broader context of this research field. However, they understand the following future work is required:\n",
    "* Defining the complete engineering scope of Practical Automated Ontologization for AES HED\n",
    "* Inferring ontological relationships between heterogeneous data fields\n",
    "* Investigating the potential for collaboration with other research institutions to pool resources and data\n",
    "* Evaluating the effectiveness of the ontology in practice and making necessary adjustments based on feedback from researchers\n",
    "* Exploring the potential for machine learning algorithms to predict outcomes based on the AES data\n",
    "Jargon and Entities\n",
    "AES: Advanced Materials Science.\n",
    "\n",
    "\n",
    "HED: Heterogeneous Experimental Data.\n",
    "\n",
    "\n",
    "AES HED: The subproblem under research.\n",
    "\n",
    "\n",
    "Hydrogen Energy Devices: Water electrolyzers and fuel cells.\n",
    "\n",
    "\n",
    "FAIR: Findable, Accessible, Interoperable, and Reusable\n",
    "\n",
    "\n",
    "neo4j: an industry-standard graph database\n",
    "\n",
    "\n",
    "EMMO: EMMO, or the European Materials Modelling Ontology, is a versatile ontology for materials sciences developed by the European Materials Modelling Council. It consists of three levels: the top level defines real-world objects and introduces \"perspectives\" to reflect their pluralistic nature, the middle level contains specific perspectives that make EMMO applicable to various domains, and the bottom level contains ontologies of specific materials science domains. EMMO is used to standardize the knowledge representation of a domain, making it particularly useful in the context of FAIR (Findable, Accessible, Interoperable, Reusable) data generation.\n",
    "\n",
    "\n",
    "VIMI:  Virtual Materials Intelligence platform, is a system that integrates data-driven methods for materials science research. It uses the Python framework Django for seamless integration and data management. The platform is designed to handle data from fabrication workflows, measurements, and simulations and encourages researchers to share data to accelerate their research. VIMI is particularly useful in the field of energy materials, where it can assist in the screening of materials, experimental design, the optimization of workflows, and the orchestration of devices within self-driven labs. VIMI is a spin-off Project from the Institute of Energy and Climate Research, IEK-13 at Forschungszentrum Juelich.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fafdc7c-946f-4027-93c9-0bf81e5e9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = f\"\"\"\n",
    "What sections should be in a proof of concept notebook for doing zero-shot prediction of materials science ontology classes from experimental csv data headers?\n",
    "\n",
    "For context, the engineering proposal is given in <one-pager>\n",
    "\n",
    "<one-pager>\n",
    "{one_pager}\n",
    "</one-pager>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b5f67-029e-4dc7-97a7-3b1075b536bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_md(gpt4(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1179d-92ae-4ac0-86de-05da580d3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_md(llama2(input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
